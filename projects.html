<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-MHBBVRYWT8"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-MHBBVRYWT8');
		</script>
		<title>CAV Lab - Emory CS</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<div id="topwrapper">
										<div><a href="index.html" class="logo"><strong>CAV</strong> Lab</a></div>
										<div><ul class="topnav">
											<li><a href="index.html">Home</a></li>
											<li><a href="index.html#news">News</a></li>
											<li><a href="projects.html">Projects</a></li>
											<li><a href="publications.html">Publications</a></li>
											<li><a href="index.html#people">People</a></li>
										</ul></div>
										<div></div>
									</div>
								</header>

							<!-- Content -->

								<!--<section>
									<header class="main">
										<h2>University Admissions</h2>
									</header>
									
									<img src="media/images/TEASER.png" alt="" width="30%" style="float:left;"/>
									<div style="padding-left: 35%;">
										<p>DESCRIPTION.</p>
										<p><a href="media/papers/LINK.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE VIS 2021.</p>
										<p><a href="https://vitality-vis.github.io"><i class="fa fa-globe" aria-hidden="true"></i> Try it out</a> on the web.</p> 
									</div>
								</section>-->

								<section>
									<header class="main">
										<h2><i class="icon fa fa-brain"></i> Belief Elicitation</h2>
									</header>
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/vibe.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>In this paper, we synthesize a design space for belief-driven visualizations based on formative and summative interviews with designers and visualization experts. The design space includes 7 main de- sign considerations, beginning with an assumed data set, then structured according to: from who, why, when, what, and how the belief is elicited, and the possible feedback about the belief that may be provided to the visualization viewer. The design space covers considerations such as the type of data parameter with optional uncertainty being elicited, interaction techniques, and visual feedback, among others. Finally, we describe how more than 24 existing belief-driven visualizations from popular news media outlets span the design space and discuss trends and opportunities within this space.</p>
											<p><a href="media/papers/VIBEEuroVis22.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from EuroVIS 2022.</p>
										
										</div>
									</div>

									<hr class="minor" />
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/belief_persistence_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
									
											<p>In this study, we recruit 101 participants to complete three tasks where beliefs are elicited immediately after seeing new data and again after a brief dis- tractor task. We conduct (1) a quantitative analysis of the results to understand if there are any systematic differences in beliefs elicited immediately after seeing new data or after a distractor task and (2) a qualitative analysis of participants’ reflections on the reasons for their belief update. While we find no statistically significant global trends across the participants beliefs elicited immediately v. after the delay, the qualitative analysis provides rich insight into the reasons for an individual’s belief movement across 9 prototypical scenarios, which includes (i) decay of beliefs as a result of either forgetting the information shown or strongly held prior beliefs, (ii) strengthening of confidence in updated beliefs by positively integrating the new data and (iii) maintaining a consistently updated belief over time, among others. These results can guide subsequent experiments to disambiguate when and by what mechanism new data is truly incorporated into one’s belief system.</p>
											<p><a href="media/papers/BeliefPersistenceEUROVIS23.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from EuroVIS 2023.</p>
										</div>
									</div>

								</section>

								<section>
									<header class="main">
										<h2><i class="icon fa fa-search"></i> Bias Detection</h2>
									</header>
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/warning_vis2017_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>User interaction patterns are a powerful tool for making inferences about the person performing those interactions. In this paper, we introduce a set of metrics to statistically characterize those interactions according to how much they deviate from an "unbiased" distribution of interactions with the data using concepts of <i>coverage</i> and <i>distribution</i>. These metrics can be applied to real-time interactions with an interface to capture potential biases over time.</p>
											<p><a href="media/papers/BiasVAST17.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE VIS 2017.</p>
										
										</div>
									</div>

									<hr class="minor" />
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/dke.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We demonstrate that the Dunning-Kruger Effect exists in a spatial reasoning task: the 15-puzzle game. Furthermore, we demonstrate that the effect leads to different patterns in user interactive behavior and has correlations with personality characteristics.</p>
											<p><a href="media/papers/DKTREX22.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from the TREX Workshop at IEEE VIS 2022.</p>
											
										</div>
									</div>

									<hr class="minor" />
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/dke_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We explore if and how DKE manifests in visual reasoning and
												judgment tasks. Across two online user studies involving (1) a sliding puzzle game and (2) a scatterplot-based categorization task, we demonstrate that individuals are susceptible to DKE in visual reasoning and judgment tasks: those who performed best underestimated their performance, while bottom performers overestimated their performance. In addition, we contribute novel analyses that correlate susceptibility of DKE with personality traits and user interactions. Our findings pave the way for novel modes of bias detection via interaction patterns and establish promising directions towards interventions tailored to an individual’s personality traits.
											</p>
											<p><a href="media/papers/DKEVIS24.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE VIS 2024.</p>
										
										</div>
									</div>

								</section>


								<section>
									<header class="main">
										<h2><i class="icon fa fa-cogs"></i> Designing Bias Mitigation Interventions</h2>
									</header>
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/design_space_vis2019_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We derive a design space comprised of 8 dimensions that can be manipulated to impact a user’s cognitive and analytic processes and describe them through an example hiring scenario. This design space can be used to guide and inform future vis systems that may integrate cognitive processes more closely.</p>
											<p><a href="media/papers/DesignSpaceVISSHORT2019.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE VIS 2019.</p> 
										</div>
									</div>

									<hr class="minor" />
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/lrg_vis2021_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We implemented one intervention, interaction traces, in the Lumos system and conducted a series of experiments to test the effectiveness.</p>
											<p><a href="media/papers/LumosVIS21.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the Lumos paper</a> from IEEE VIS 2021.</p> 
											<p><a href="media/papers/LRGVIS21.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the Left, Right, and Gender paper</a> from IEEE VIS 2021.</p>
										</div>
									</div>


									<hr class="minor" />
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/LOR_bias_teaser.png" alt="" style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We conducted a crowdsourced experiment that showed biased language can have a negative impact on readers’ evaluations of candidates and visual highlighting of specific types of language in letters of recommendation has the potential to influence the evaluation of candidates. Specifically, we found that highlighting language more commonly used to describe female can negatively affect readers’ evaluation of candidates, while highlighting language more commonly used to describe male can reduce the effects of the bias.</p>
											<p><a href="media/papers/LORBiasVIS4GOOD23.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from the VIS4Good workshop at IEEE VIS 2023.</p>
										</div>
									</div>



								</section>

								<section>
									<header class="main">
										<h2><i class="icon fa fa-project-diagram"></i> Transformer-Based Interactive Literature Review</h2>
									</header>
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/vitality_vis2021_teaser.png" alt=""  style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We developed an interactive table-based visualization for searching academic literature using a transformer-based approach. The system, VitaLITy, has an initial set of 59k articles from popular visualization venues. The open-source code can be augmented to search literature from other academic sources as well. An alternative to keyword searches, find semantically similar documents by providing a set of initial seed papers or providing a working paper title and abstract to kickstart the literature review of a new project idea.</p>
											<p><a href="media/papers/VitaLITyVIS21.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE VIS 2021.</p>
											<p><a href="media/papers/VitaLITy2NLVIZ24.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out VitaLITy 2.0 </a> from the NLVIZ workshop at IEEE VIS 2024.</p>
											<p><a href="https://vitality-vis.github.io"><i class="fa fa-globe" aria-hidden="true"></i> Try it out</a> on the web.</p> 
										</div>
									</div>
								</section>
								<section>
									<header class="main">
										<h2><i class="icon fa fa-check-square"></i> Visualization Evaluation</h2>
									</header>
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/ICE-T_teaser.png" alt=""  style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations.
												We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics.</p>
											<p><a href="media/papers/ValueVIS18.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE InfoVis 2018.</p>
											<p><a href="https://visvalue.github.io/"><i class="fa fa-globe" aria-hidden="true"></i> Check out the project website</a></p> 
										</div>

									</div>
									<hr class="minor">
									<div style="display: flex; align-items: stretch;">
										<img src="media/images/VisHiker_teaser.png" alt=""  style="width: 30%; object-fit: contain;"/>
										<div style="padding-left: 5%; flex-grow: 1;">
											<p>We describe the persistent tensions between various camps on the “right” way to conduct evaluations in visualization. Visualization as a field is the amalgamation of cognitive and perceptual sciences and computer graphics, among others. As a result, the relatively disjointed lineages in visualization understandably approach the topic of evaluation very differently. We explicate these differing expectations and conventions to appreciate the spectrum of evaluation design decisions. We describe some guiding questions that researchers may consider when designing evaluations to navigate differing readers’ evaluation expectations.</p>
											<p><a href="media/papers/VisHikerViewpoint22.pdf"><i class="fa fa-file" aria-hidden="true"></i> Check out the paper</a> from IEEE CG&A 2022.</p>
											
										</div>

									</div>

								</section>
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>